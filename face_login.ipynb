{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "from tkinter import  Message, Text\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np \n",
    "import cv2\n",
    "from PIL import  Image, ImageTk\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import tkinter.ttk as ttk\n",
    "import tkinter.font as font\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set window properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "font_size = ('times', 15, 'bold')\n",
    "green = 'green'\n",
    "white = 'white'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Face Recognizer\")\n",
    "window.configure(background='white')\n",
    "window.grid_rowconfigure(0, weight=1)\n",
    "window.grid_columnconfigure(0, weight=1)\n",
    "message = tk.Label(\n",
    "   window, text=\"Face-Recognition-System\",\n",
    "   bg='green', fg='white', width=50, height=3, font=('times', 30, 'bold')  \n",
    ")\n",
    "message.place(x=200, y=20)\n",
    "\n",
    "lbl = tk.Label(window, text=\"No.\", width=20, height=2, fg=green, bg=white, font=font_size)\n",
    "lbl.place(x=400, y=200)\n",
    "\n",
    "txt = tk.Entry(window, width=20, fg=green, bg=white ,font=font_size)\n",
    "txt.place(x=700, y=215)\n",
    "\n",
    "lbl2 = tk.Label(window, text=\"Name\", width=20, fg=green, bg=white, height=2, font=font_size)\n",
    "lbl2.place(x=400, y=300)\n",
    "\n",
    "txt2 = tk.Entry(window, width=20, bg=white, fg=green, font=font_size)\n",
    "txt2.place(x=700, y=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to Check whether a text is number or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumber(s):\n",
    "   try:\n",
    "      float(s)\n",
    "      return True\n",
    "   except ValueError:\n",
    "      pass\n",
    "   try:\n",
    "      import unicodedata\n",
    "      unicodedata.numeric(s)\n",
    "      return True\n",
    "   except (TypeError, ValueError):\n",
    "      pass\n",
    "   return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to take images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeImages():\n",
    "   # Both ID and Name is used for recognizing the Image\n",
    "   Id = (txt.get())\n",
    "   name = (txt2.get())\n",
    "\n",
    "   #check if the Id is numeric and name is alphabetical\n",
    "   if(isNumber(Id) and name.isalpha()):\n",
    "      # opening the primary camera if you want to access\n",
    "      # the secondary camera you can mention the number as 1 inside the parenthesis\n",
    "      cam = cv2.VideoCapture(1)\n",
    "\n",
    "      # Specifying the path to haarcascade file\n",
    "      harcascadePath = 'data\\haarcascade_frontalface_default.xml'\n",
    "\n",
    "      # Creating the classier based on the haarcascade file.\n",
    "      detector = cv2.CascadeClassifier(harcascadePath)\n",
    "\n",
    "      # initializing the sample number (No. of images) as 0\n",
    "      sampleNum = 0 \n",
    "      while(True):\n",
    "         # Reading the video captures by camera frame by frame\n",
    "         ret, img = cam.read()\n",
    "\n",
    "         # converting the image into grayscale as most of \n",
    "         # the processing is done in grayscale format\n",
    "         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "         # it converts the images in different sizes (decreases by 1.3 times)\n",
    "         # and 5 specifies the number of times scaling happens\n",
    "         faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "         #for creating a rectangle around the image\n",
    "         for (x,y,w,h) in faces:\n",
    "            # specify the cordinates of the image as well as color and thickness of the rectangles,\n",
    "            # incrementing sample number for each image\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0,0), 2)\n",
    "            sampleNum += 1\n",
    "\n",
    "            # save the captured face in the dataset folder TrainingImage as the image needs to be \n",
    "            # trained are saved in this folder\n",
    "            cv2.imwrite(\"TrainingImage\\ \" + name +\".\" + Id + \".\" + str(sampleNum) + \".jpg\", gray[y:y+h, x:x+w])\n",
    "\n",
    "            # display the frame that has been captured and drawn rectangle around it\n",
    "            cv2.imshow('frame', img)\n",
    "         \n",
    "         # wait for 100 milliseconds\n",
    "         if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "         # break if the sample number is more than 60\n",
    "         elif sampleNum > 60:\n",
    "            break\n",
    "      # releasing the resources\n",
    "      cam.release()\n",
    "\n",
    "      # closing all the windows\n",
    "      cv2.destroyAllWindows()\n",
    "\n",
    "      # displaying message for the user\n",
    "      res = \"Images Saved for ID : \" + Id + \"Name : \" + name\n",
    "\n",
    "      # creating the entry for the user in a csv file\n",
    "      row = [Id, name]\n",
    "      with open('UserDetails\\ UserDetails.csv', 'a+') as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         # Entry of the row in csv file\n",
    "         writer.writerow(row)\n",
    "      message.configure(text=res)\n",
    "   elif (isNumber(Id)):\n",
    "      res = \"Enter Alphabetical Name\"\n",
    "      message.configure(text=res)\n",
    "   elif (name.isalpha()):\n",
    "      res = \"Enter Numeric Id\"\n",
    "      message.configure(text=res)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the images saved in training image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesAndLabels(path):\n",
    "      # get the path of all the files in the folder\n",
    "      imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "      faces = []\n",
    "\n",
    "      # create empyty Id list\n",
    "      ids = []\n",
    "\n",
    "      # now loop through all the image paths and load the Ids and the images saved in the folder\n",
    "      for imagePath in imagePaths:\n",
    "         # load the image and convert it to grayscale\n",
    "         pillimage = Image.open(imagePath).convert('L')\n",
    "\n",
    "         # now convert the PIL image into numpy array\n",
    "         imageNp = np.array(pillimage, 'uint8')\n",
    "\n",
    "         # get the Id from the image\n",
    "         Id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "\n",
    "         # extract the face from the training image samples\n",
    "         faces.append(imageNp)\n",
    "         ids.append(Id)\n",
    "         return faces, ids\n",
    "      \n",
    "def trainImages():\n",
    "   # local Binary Pattern Histogram is a Face Recognizer algorithm inside OpenCV\n",
    "   # module used for training the image dataset\n",
    "   recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "   # specify the path for HaarCascade file\n",
    "   harcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "\n",
    "   # create detector for faces\n",
    "   detector = cv2.CascadeClassifier(harcascadePath)\n",
    "\n",
    "   # saving the detected faces in variables\n",
    "   faces, Id = getImagesAndLabels(\"TrainingImage\")\n",
    "\n",
    "   # save the trained faces and their respective Id's in a model named as \"trainner.yml\"\n",
    "   recognizer.train(faces, np.array(Id))\n",
    "   recognizer.save(\"TrainingImageLabel\\Trainner.yml\")\n",
    "\n",
    "   # displaying the message\n",
    "   res = \"Image Trained\"\n",
    "   message.configure(text=res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackImages():\n",
    "   recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "   # read the trained model\n",
    "   recognizer.read(\"TrainingImageLabel\\Trainer.yml\")\n",
    "   harcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "\n",
    "   faceCascade = cv2.CascadeClassifier(harcascadePath)\n",
    "\n",
    "   # get the name from 'userdetails.csv'\n",
    "   df = pd.read_csv(\"UserDetails\\ UserDetails.csv\")\n",
    "   cam = cv2.VideoCapture(0)\n",
    "   font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "   while True:\n",
    "      ret, im = cam.read()\n",
    "      gray = cv2.cvtColot(im, cv2.COLOR_BGR2GRAY)\n",
    "      faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "      for (x,y,w,h) in faces:\n",
    "         cv2.rectangle(im, (x,y), (x+w, y+h), (225, 0,0), 2)\n",
    "         Id, conf = recognizer.predict(gray[y:y+h, x:x+w])\n",
    "         if(conf < 50):\n",
    "            aa = df.loc[df['Id'] == Id]['Name'].values \n",
    "            tt = str(Id) + \".\" + aa \n",
    "         else:\n",
    "            Id = 'Unknown'\n",
    "            tt = str(Id)\n",
    "            if(conf > 75):\n",
    "               noOfFile = len(os.listdir(\"imagesUnknown\")) + 1\n",
    "               cv2.imwrite(\"ImagesUnknown\\Image\" + str(noOfFile) + '.jpg', im[y:y+h, x:x+w])\n",
    "               cv2.putText(im, str(tt), (x,y+h), font, 1, (255,255,255), 2)\n",
    "               cv2.imshow('im', im)\n",
    "      if(cv2.waitKey(1) == ord('q')):\n",
    "         break\n",
    "      cam.realease()\n",
    "      cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeImgBtn = tk.Button(window, text = \"Sample\", command=takeImages, fg=white, bg=green, width=20, height=3, activebackground=\"Red\", font=font_size)\n",
    "takeImgBtn.place(x=200, y=500)\n",
    "\n",
    "trainImgBtn = tk.Button(window, text=\"Training\", command=trainImages, fg=white, bg=green, width=20, height=3, activebackground=\"Red\", font=font_size)\n",
    "trainImgBtn.place(x=500, y=500)\n",
    "\n",
    "trackImgBtn = tk.Button(window, text=\"Testing\", command=trackImages, fg=white, bg=green, width=20, height=3, activebackground=\"Red\", font=font_size)\n",
    "trackImgBtn.place(x=800, y=500)\n",
    "\n",
    "quitWindowBtn = tk.Button(window, text='Quit', command=window.destroy, fg=white, bg=green, width=20, height=3, activebackground=\"Red\", font=font_size)\n",
    "quitWindowBtn.place(x=1100, y=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@363.856] global /croot/opencv-suite_1691620365762/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@363.857] global /croot/opencv-suite_1691620365762/work/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@363.857] global /croot/opencv-suite_1691620365762/work/modules/core/src/persistence.cpp (505) open Can't open file: 'data\\haarcascade_frontalface_default.xml' in read mode\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kratosgado/anaconda3/lib/python3.11/tkinter/__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_37111/420980957.py\", line 26, in takeImages\n",
      "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cv2.error: OpenCV(4.6.0) /croot/opencv-suite_1691620365762/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "[ WARN:0@366.486] global /croot/opencv-suite_1691620365762/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@366.486] global /croot/opencv-suite_1691620365762/work/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@366.487] global /croot/opencv-suite_1691620365762/work/modules/core/src/persistence.cpp (505) open Can't open file: 'data\\haarcascade_frontalface_default.xml' in read mode\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kratosgado/anaconda3/lib/python3.11/tkinter/__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_37111/420980957.py\", line 26, in takeImages\n",
      "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cv2.error: OpenCV(4.6.0) /croot/opencv-suite_1691620365762/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfdbfd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
